{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import gpytorch\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "\n",
    "from gpytorch.models import ExactGP\n",
    "from gpytorch.likelihoods import DirichletClassificationLikelihood\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r'../../data/olhs_run1.xlsx'\n",
    "x_pd = pd.read_excel(filename, sheet_name='Initial Design (OLHS)', header=[0,1], index_col=[0])\n",
    "y_pd = pd.read_excel(filename, sheet_name='feasibility', header=[0,1], index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmeans = x_pd.mean(axis=0)\n",
    "xstddv = x_pd.std(axis=0)\n",
    "x_pd_normal = (x_pd - xmeans)/xstddv\n",
    "x_pd = x_pd_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement K-fold cross-validation - returns list - each fold arranged as indices (train_idx, test_idx)\n",
    "def kfold_split(data, num_folds):\n",
    "    fold_size = len(data) // num_folds\n",
    "    # indices = np.arange(len(data)) \n",
    "    indices = np.random.permutation(len(data))\n",
    "    folds = []\n",
    "    for i in range(num_folds):\n",
    "        test_indices = indices[i * fold_size: (i + 1) * fold_size]\n",
    "        train_indices = np.concatenate([indices[:i * fold_size], indices[(i + 1) * fold_size:]])\n",
    "        folds.append((train_indices, test_indices))\n",
    "    return folds\n",
    "\n",
    "#function to calculate class probabilities \n",
    "def class_probability(X, model, likl):\n",
    "    with torch.no_grad():\n",
    "        logit_dist = model(X)\n",
    "        pred_dist = likl(logit_dist, noise=torch.zeros(X.shape[0]))\n",
    "    samples = logit_dist.sample(torch.Size((256,))).exp()\n",
    "    return pred_dist, (samples / samples.sum(-2, keepdim=True)).mean(0) # logit distribution, probability vectors\n",
    "\n",
    "#funciton to count misclassifications\n",
    "def class_count(pred, target):\n",
    "    return np.sum(np.abs(pred - target))/len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the simplest form of GP model, exact inference\n",
    "class DirichletGPModel(ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, num_classes):\n",
    "        super(DirichletGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = ConstantMean(batch_shape=torch.Size((num_classes,)))\n",
    "        self.covar_module = ScaleKernel(\n",
    "            RBFKernel(batch_shape=torch.Size((num_classes,))),\n",
    "            batch_shape=torch.Size((num_classes,)),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# function to optimize parameters of the classification GP - \n",
    "def train_cls_gp(model, likelihood, train_x, training_iter):\n",
    "   # Find optimal model hyperparameters\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    # Use the adam optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    for i in range(training_iter):\n",
    "        # Zero gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        # Output from model\n",
    "        output = model(train_x)\n",
    "        # Calc loss and backprop gradients\n",
    "        loss = -mll(output, likelihood.transformed_targets).sum()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return model, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gouravkumbhojkar/miniconda3/envs/myenv/lib/python3.11/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "folds = kfold_split(x_pd.values, num_folds=20)\n",
    "all_x = torch.tensor(x_pd.values, dtype=torch.float)\n",
    "all_y = torch.tensor(y_pd.values, dtype=torch.long)\n",
    "\n",
    "train_accuracy_history = []\n",
    "val_accuracy_history = []\n",
    "\n",
    "# train_class0_prob = []\n",
    "# val_class0_prob = []\n",
    "\n",
    "for train_idx, valdn_idx in folds:\n",
    "    train_x, train_y = all_x[train_idx, :], all_y[train_idx, :].flatten()\n",
    "    valdn_x, valdn_y = all_x[valdn_idx, :], all_y[valdn_idx, :].flatten()\n",
    "\n",
    "    #initialize model and likelihood\n",
    "    likelihood = DirichletClassificationLikelihood(train_y, learn_additional_noise=False, alpha_epsilon=1e-4)\n",
    "    model = DirichletGPModel(train_x, likelihood.transformed_targets, likelihood, num_classes=likelihood.num_classes)\n",
    "\n",
    "    #train model\n",
    "    model, likelihood = train_cls_gp(model, likelihood, train_x, training_iter=50)\n",
    "\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "    #prediction\n",
    "    train_logit_dist, training_probs = class_probability(train_x, model, likelihood)\n",
    "    val_logit_dist, val_probs = class_probability(valdn_x, model, likelihood)\n",
    "\n",
    "    #misclassification count\n",
    "    training_accuracy = 1 - class_count(training_probs.max(0)[1].numpy(), train_y.numpy())\n",
    "    valdn_accuracy = 1 - class_count(val_probs.max(0)[1].numpy(), valdn_y.numpy())\n",
    "\n",
    "    train_accuracy_history.append(training_accuracy)\n",
    "    val_accuracy_history.append(valdn_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_accuracy_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7894736842105263,\n",
       " 1.0,\n",
       " 0.8947368421052632,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.8421052631578947,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.8421052631578947,\n",
       " 1.0,\n",
       " 0.7894736842105263,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accuracy_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([12, 19,  9,  0, 15,  7, 13, 14,  4, 18,  3, 10,  1, 16, 11,  8, 17,\n",
       "          6,  5]),\n",
       "  array([2])),\n",
       " (array([ 2, 19,  9,  0, 15,  7, 13, 14,  4, 18,  3, 10,  1, 16, 11,  8, 17,\n",
       "          6,  5]),\n",
       "  array([12])),\n",
       " (array([ 2, 12,  9,  0, 15,  7, 13, 14,  4, 18,  3, 10,  1, 16, 11,  8, 17,\n",
       "          6,  5]),\n",
       "  array([19])),\n",
       " (array([ 2, 12, 19,  0, 15,  7, 13, 14,  4, 18,  3, 10,  1, 16, 11,  8, 17,\n",
       "          6,  5]),\n",
       "  array([9])),\n",
       " (array([ 2, 12, 19,  9, 15,  7, 13, 14,  4, 18,  3, 10,  1, 16, 11,  8, 17,\n",
       "          6,  5]),\n",
       "  array([0])),\n",
       " (array([ 2, 12, 19,  9,  0,  7, 13, 14,  4, 18,  3, 10,  1, 16, 11,  8, 17,\n",
       "          6,  5]),\n",
       "  array([15])),\n",
       " (array([ 2, 12, 19,  9,  0, 15, 13, 14,  4, 18,  3, 10,  1, 16, 11,  8, 17,\n",
       "          6,  5]),\n",
       "  array([7])),\n",
       " (array([ 2, 12, 19,  9,  0, 15,  7, 14,  4, 18,  3, 10,  1, 16, 11,  8, 17,\n",
       "          6,  5]),\n",
       "  array([13])),\n",
       " (array([ 2, 12, 19,  9,  0, 15,  7, 13,  4, 18,  3, 10,  1, 16, 11,  8, 17,\n",
       "          6,  5]),\n",
       "  array([14])),\n",
       " (array([ 2, 12, 19,  9,  0, 15,  7, 13, 14, 18,  3, 10,  1, 16, 11,  8, 17,\n",
       "          6,  5]),\n",
       "  array([4])),\n",
       " (array([ 2, 12, 19,  9,  0, 15,  7, 13, 14,  4,  3, 10,  1, 16, 11,  8, 17,\n",
       "          6,  5]),\n",
       "  array([18])),\n",
       " (array([ 2, 12, 19,  9,  0, 15,  7, 13, 14,  4, 18, 10,  1, 16, 11,  8, 17,\n",
       "          6,  5]),\n",
       "  array([3])),\n",
       " (array([ 2, 12, 19,  9,  0, 15,  7, 13, 14,  4, 18,  3,  1, 16, 11,  8, 17,\n",
       "          6,  5]),\n",
       "  array([10])),\n",
       " (array([ 2, 12, 19,  9,  0, 15,  7, 13, 14,  4, 18,  3, 10, 16, 11,  8, 17,\n",
       "          6,  5]),\n",
       "  array([1])),\n",
       " (array([ 2, 12, 19,  9,  0, 15,  7, 13, 14,  4, 18,  3, 10,  1, 11,  8, 17,\n",
       "          6,  5]),\n",
       "  array([16])),\n",
       " (array([ 2, 12, 19,  9,  0, 15,  7, 13, 14,  4, 18,  3, 10,  1, 16,  8, 17,\n",
       "          6,  5]),\n",
       "  array([11])),\n",
       " (array([ 2, 12, 19,  9,  0, 15,  7, 13, 14,  4, 18,  3, 10,  1, 16, 11, 17,\n",
       "          6,  5]),\n",
       "  array([8])),\n",
       " (array([ 2, 12, 19,  9,  0, 15,  7, 13, 14,  4, 18,  3, 10,  1, 16, 11,  8,\n",
       "          6,  5]),\n",
       "  array([17])),\n",
       " (array([ 2, 12, 19,  9,  0, 15,  7, 13, 14,  4, 18,  3, 10,  1, 16, 11,  8,\n",
       "         17,  5]),\n",
       "  array([6])),\n",
       " (array([ 2, 12, 19,  9,  0, 15,  7, 13, 14,  4, 18,  3, 10,  1, 16, 11,  8,\n",
       "         17,  6]),\n",
       "  array([5]))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avarge accuracy on training data -  0.9578947368421054\n",
      "Average accuracy on validation data -  0.7\n"
     ]
    }
   ],
   "source": [
    "# average accuracy of the model\n",
    "mean_train_accuracy = np.mean(np.array(train_accuracy_history))\n",
    "mean_val_accuracy = np.mean(np.array(val_accuracy_history))\n",
    "print('Avarge accuracy on training data - ', mean_train_accuracy)\n",
    "print('Average accuracy on validation data - ', mean_val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment on cross-validation results**\n",
    "\n",
    "Data is biased. Only 6 data points are infeasible. Split should be done according to the bias?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
