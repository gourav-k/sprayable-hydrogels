{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import gpytorch\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r'../data/olhs_run1.xlsx'\n",
    "x_pd = pd.read_excel(filename, sheet_name='Initial Design (OLHS)', header=[0,1], index_col=[0])\n",
    "y_pd = pd.read_excel(filename, sheet_name='bo_data', header=[0,1], index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing the inputs\n",
    "xmeans = x_pd.mean(axis=0)\n",
    "xstddv = x_pd.std(axis=0)\n",
    "x_pd_normal = (x_pd - xmeans)/xstddv\n",
    "\n",
    "x_pd = x_pd_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize objective value data\n",
    "y_obj_pd = y_pd.iloc[:, [0,1,2]]\n",
    "ymeans = y_obj_pd.mean(axis=0)\n",
    "ystddv = y_obj_pd.std(axis=0)\n",
    "y_obj_pd_normal = (y_obj_pd - ymeans) / ystddv\n",
    "\n",
    "y_pd.iloc[:, [0,1,2]] = y_obj_pd_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_idx = [1,7,15]\n",
    "\n",
    "train_x_pd = x_pd.drop(validation_idx)\n",
    "train_y_pd = y_pd.drop(validation_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make torch tensors\n",
    "train_x = torch.tensor(train_x_pd.values, dtype=torch.float)\n",
    "train_y1 = torch.tensor(train_y_pd['Polymer Solubility', 'mg/mL'].values, dtype=torch.float).squeeze()\n",
    "train_y2 = torch.tensor(train_y_pd['Gelation Enthalpy', 'J/g'].values, dtype=torch.float).squeeze()\n",
    "train_y3 = torch.tensor(train_y_pd['Shear Modulus', 'Kpa'].values, dtype=torch.float).squeeze()\n",
    "train_y4 = torch.tensor(train_y_pd['Manufacturability', '--'].values, dtype=torch.long).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = torch.tensor(x_pd.values, dtype=torch.float)\n",
    "test_y = torch.tensor(y_pd.values, dtype=torch.float).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "    \n",
    "# function to optimize parameters of the regression GP -\n",
    "def train_reg_gp(model, likelihood, train_x, train_y, training_iter):\n",
    "   # Find optimal model hyperparameters\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    # Use the adam optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    for i in range(training_iter):\n",
    "        # Zero gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        # Output from model\n",
    "        output = model(train_x)\n",
    "        # Calc loss and backprop gradients\n",
    "        loss = -mll(output, train_y)\n",
    "        loss.backward()\n",
    "        if i - 1  == training_iter:\n",
    "            print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "                i + 1, training_iter, loss.item(),\n",
    "                model.covar_module.base_kernel.lengthscale.item(),\n",
    "                model.likelihood.noise.item()\n",
    "            ))\n",
    "        optimizer.step()\n",
    "\n",
    "    return model, likelihood "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirichletGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, num_classes):\n",
    "        super(DirichletGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean(batch_shape=torch.Size((num_classes,)))\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel(batch_shape=torch.Size((num_classes,))),\n",
    "            batch_shape=torch.Size((num_classes,)),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# function to optimize parameters of the classification GP - \n",
    "def train_cls_gp(model, likelihood, train_x, training_iter):\n",
    "   # Find optimal model hyperparameters\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    # Use the adam optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    for i in range(training_iter):\n",
    "        # Zero gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        # Output from model\n",
    "        output = model(train_x)\n",
    "        # Calc loss and backprop gradients\n",
    "        loss = -mll(output, likelihood.transformed_targets).sum()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return model, likelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_likl = gpytorch.likelihoods.GaussianLikelihood()\n",
    "reg_model1 = ExactGPModel(train_x, train_y1, reg_likl)\n",
    "reg_model2 = ExactGPModel(train_x, train_y2, reg_likl)\n",
    "reg_model3 = ExactGPModel(train_x, train_y3, reg_likl)\n",
    "\n",
    "cls_likl = gpytorch.likelihoods.DirichletClassificationLikelihood(train_y4, learn_additional_noise=False, alpha_epsilon=1e-4)\n",
    "cls_model = DirichletGPModel(train_x, cls_likl.transformed_targets, cls_likl, num_classes=cls_likl.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_iter = 50\n",
    "\n",
    "reg_model1, reg_likl1 = train_reg_gp(reg_model1, reg_likl, train_x, train_y1, training_iter)\n",
    "reg_model2, reg_likl2 = train_reg_gp(reg_model2, reg_likl, train_x, train_y2, training_iter)\n",
    "reg_model3, reg_likl3 = train_reg_gp(reg_model3, reg_likl, train_x, train_y3, training_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_model, cls_likl = train_cls_gp(cls_model, cls_likl, train_x, training_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
